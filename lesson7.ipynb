{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JGJE7TB_xjSq"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.probability import FreqDist\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from string import punctuation\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchsummary import summary\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RANDOM_STATE = 29"
      ],
      "metadata": {
        "id": "RI_-fQx4yiLx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv('/content/train.csv', index_col='id')\n",
        "print(df_train.shape)\n",
        "df_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "WEDIFizeymwM",
        "outputId": "73e324dd-aab5-4b42-bc7c-f4ff8d819142"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(31962, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    label                                              tweet\n",
              "id                                                          \n",
              "1       0   @user when a father is dysfunctional and is s...\n",
              "2       0  @user @user thanks for #lyft credit i can't us...\n",
              "3       0                                bihday your majesty\n",
              "4       0  #model   i love u take with u all the time in ...\n",
              "5       0             factsguide: society now    #motivation"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-74959ec8-275a-4823-ba72-10e89c75ad17\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-74959ec8-275a-4823-ba72-10e89c75ad17')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-74959ec8-275a-4823-ba72-10e89c75ad17 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-74959ec8-275a-4823-ba72-10e89c75ad17');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Описание датасета:\n",
        "The objective of this task is to detect hate speech in tweets.\n",
        "For the sake of simplicity, we say a tweet contains hate speech\n",
        "if it has a racist or sexist sentiment associated with it.\n",
        "So, the task is to classify racist or sexist tweets from other tweets.\n",
        "\n",
        "Formally, given a training sample of tweets and labels, where label '1'\n",
        "denotes the tweet is racist/sexist and label '0' denotes the tweet is\n",
        "not racist/sexist, your objective is to predict the labels on the test dataset.\n",
        "\n",
        "Таким образом, нам нужно будет искать твиты, которые содержат\n",
        "расистский или сексистский смысл."
      ],
      "metadata": {
        "id": "VMu5XBVey3Pt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.read_csv('/content/test.csv', index_col='id')\n",
        "print(df_test.shape)\n",
        "df_test.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "R8DcN0X6yux_",
        "outputId": "4bf985e0-15f5-499f-a8df-1b303b949aa3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(17197, 1)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   tweet\n",
              "id                                                      \n",
              "31963  #studiolife #aislife #requires #passion #dedic...\n",
              "31964   @user #white #supremacists want everyone to s...\n",
              "31965  safe ways to heal your #acne!!    #altwaystohe...\n",
              "31966  is the hp and the cursed child book up for res...\n",
              "31967    3rd #bihday to my amazing, hilarious #nephew..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5ecf7da2-5ecf-4b65-8baa-abbd4423f16c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>31963</th>\n",
              "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31964</th>\n",
              "      <td>@user #white #supremacists want everyone to s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31965</th>\n",
              "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31966</th>\n",
              "      <td>is the hp and the cursed child book up for res...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31967</th>\n",
              "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5ecf7da2-5ecf-4b65-8baa-abbd4423f16c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5ecf7da2-5ecf-4b65-8baa-abbd4423f16c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5ecf7da2-5ecf-4b65-8baa-abbd4423f16c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Так как тестовые данные не содержат меток, то будем использовать только\n",
        "трейн для обучения и валидации, чтобы можно было оценить качество модели.\n",
        "Посмотрим на баланс классов:"
      ],
      "metadata": {
        "id": "dd8yUCb2zDwe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWd8sI9-yvlk",
        "outputId": "4442b8e1-6501-4fe5-aede-d53376ef13ff"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    29720\n",
              "1     2242\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['label'].value_counts()[0] / df_train['label'].value_counts()[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgEMHIfmyvoJ",
        "outputId": "6eb60df2-ebb9-4ba5-ffbf-7929c93a44b8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13.256021409455842"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Как часто бывает в подобных задачах, мы имеем большой дисбаланс классов.\n",
        "\n",
        "Сделаем разбивку на трейн и валидацию:"
      ],
      "metadata": {
        "id": "XUK1wz6gzOUQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train, df_val = train_test_split(df_train, \n",
        "                                    test_size=0.2, \n",
        "                                    random_state=RANDOM_STATE, \n",
        "                                    stratify=df_train['label'])\n",
        "\n",
        "df_train.shape, df_val.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKiz5B7Yyvub",
        "outputId": "bb4a94f7-f47e-425a-faa4-1deaeb657942"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((25569, 2), (6393, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сделаем подготовку текстов:"
      ],
      "metadata": {
        "id": "5XkwKtlazUsV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_9jCSOOzVue",
        "outputId": "21b4fc0c-2031-4171-cc83-fadd8efff44e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "puncts = set(punctuation)\n",
        "# Не будем очищать текст от апострофов, заменим их потом на пробелы,\n",
        "# т.к. встроенные в nltk английские стопслова и так потом отфильтруют лишнее\n",
        "puncts = puncts - {\"'\"}"
      ],
      "metadata": {
        "id": "xhwcWYrdzVxE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "mflmVOj4zVza",
        "outputId": "2a0b1aee-ef47-4f71-8234-1e674f0ea44d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       label                                              tweet\n",
              "id                                                             \n",
              "14553      0  @user they're all amazing! can't wait to see w...\n",
              "2563       0  can't wait for the new @user trailer ð¤   #g...\n",
              "12125      0   i am thriving. #i_am #positive #affirmation     \n",
              "6326       0  happy to have new @user book, lil upset some t...\n",
              "3996       0  about to arrive in the cold rainy english noh,..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7f75ac10-e12b-488b-aec0-17f4b2b85b46\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>14553</th>\n",
              "      <td>0</td>\n",
              "      <td>@user they're all amazing! can't wait to see w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2563</th>\n",
              "      <td>0</td>\n",
              "      <td>can't wait for the new @user trailer ð¤   #g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12125</th>\n",
              "      <td>0</td>\n",
              "      <td>i am thriving. #i_am #positive #affirmation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6326</th>\n",
              "      <td>0</td>\n",
              "      <td>happy to have new @user book, lil upset some t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3996</th>\n",
              "      <td>0</td>\n",
              "      <td>about to arrive in the cold rainy english noh,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7f75ac10-e12b-488b-aec0-17f4b2b85b46')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7f75ac10-e12b-488b-aec0-17f4b2b85b46 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7f75ac10-e12b-488b-aec0-17f4b2b85b46');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подготовим общий корпус текста:"
      ],
      "metadata": {
        "id": "yV7V2AbmzkOm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_corpus = ''.join(df_train['tweet'].values)"
      ],
      "metadata": {
        "id": "2W6mvJo6zV1v"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сделаем токенизацию:"
      ],
      "metadata": {
        "id": "DLRvmngLzqXE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2hx_UVEzySF",
        "outputId": "62aacf1a-5c47-4d4d-9e4f-1447262726ad"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = word_tokenize(train_corpus)\n",
        "tokens[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHVqwqMdzrs_",
        "outputId": "593035f7-29b0-447c-f734-5be4b0d39ba3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['@', 'user', 'they', \"'re\", 'all']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создадим словарь:"
      ],
      "metadata": {
        "id": "FAHP6MRZz3_u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_WORDS = 4000\n",
        "MAX_LEN = 40"
      ],
      "metadata": {
        "id": "Re5gwaebzrvk"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dist = FreqDist(tokens)\n",
        "tokens_top = [items[0] for items in dist.most_common(MAX_WORDS - 1)]"
      ],
      "metadata": {
        "id": "hqtj6kMwzrxq"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_top[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wObXC_Sozrzh",
        "outputId": "c89c61a1-981f-40c9-98b8-f22aa681d008"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['#', '@', 'user', '!', '.', 'the', 'to', 'i', 'a', ',']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = {word: count for count, word in dict(enumerate(tokens_top, 1)).items()}"
      ],
      "metadata": {
        "id": "yZbbQkTBzr11"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Переведём твиты в набор индексов, добавим паддинг:"
      ],
      "metadata": {
        "id": "suPDAwJF0Jva"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_sequence(txt, maxlen):\n",
        "    result = []\n",
        "    tokens = word_tokenize(txt)\n",
        "    for word in tokens:\n",
        "        if word in vocabulary:\n",
        "            result.append(vocabulary[word])\n",
        "\n",
        "    padding = [0] * (maxlen-len(result))\n",
        "    return result[-maxlen:] + padding"
      ],
      "metadata": {
        "id": "kRLvqzDUzr4M"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.array([text_to_sequence(txt, MAX_LEN) for txt in df_train['tweet'].values])\n",
        "X_val = np.array([text_to_sequence(txt, MAX_LEN) for txt in df_val['tweet'].values])\n",
        "\n",
        "X_train.shape, X_val.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0dr_HY-zr5w",
        "outputId": "4c7016dd-ce97-4ba3-e5c2-ffb67557d0ea"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((25569, 40), (6393, 40))"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Оригинальная строка: {df_train['tweet'].iloc[5]}\")\n",
        "print(f\"Обработанная строка: {X_train[5]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7nL-wt10V8c",
        "outputId": "ce611990-48fd-4466-a8b6-1726bbbb6aa4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Оригинальная строка: found a beautiful one bedroom with a double stall garage, patio &amp; huge kitchen! signed our lease, can't wait to move in! ððð¦ð  \n",
            "Обработанная строка: [ 291    9  116   86   25    9 1485   10   31   38   26 1043 1840    4\n",
            " 1939   77   10   84   29  127    7 1119   13    4    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Инициализируем рекуррентную нейросеть:"
      ],
      "metadata": {
        "id": "8RfRJivK0Zrd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, vocab_size=2000, embedding_dim=128, out_dim=64, use_last=True, threshold=0.5, num_classes=1):\n",
        "        super().__init__()\n",
        "        self.threshold = threshold\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0) \n",
        "        self.gru = nn.GRU(embedding_dim, out_dim, batch_first=True) \n",
        "        self.linear = nn.Linear(out_dim, num_classes)\n",
        "        self.dp = nn.Dropout(0.5)\n",
        "        self.use_last = use_last\n",
        "        \n",
        "    def forward(self, x):                          \n",
        "        x = self.embedding(x)\n",
        "        x = self.dp(x)\n",
        "        x, _ = self.gru(x)\n",
        "           \n",
        "        if self.use_last:\n",
        "            x = x[:,-1,:]\n",
        "        else:\n",
        "            x = torch.mean(x[:,:], dim=1)\n",
        "            \n",
        "        x = self.dp(x)\n",
        "        x = self.linear(x)\n",
        "        x = torch.sigmoid(x)\n",
        "        return x\n",
        "    \n",
        "    def predict(self, x):\n",
        "        x = torch.IntTensor(x).to(device)\n",
        "        x = self.forward(x)\n",
        "        x = torch.squeeze((x > self.threshold).int())\n",
        "        return x"
      ],
      "metadata": {
        "id": "tUVyYBAx0bFD"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DataWrapper(Dataset):\n",
        "    def __init__(self, data, target):\n",
        "\n",
        "        self.data = torch.from_numpy(data)\n",
        "        self.target = torch.from_numpy(target)\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        y = self.target[index]\n",
        "            \n",
        "        return x, y\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.data.shape[0]"
      ],
      "metadata": {
        "id": "v__P0uwS0bNH"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 512"
      ],
      "metadata": {
        "id": "L0UECK_r0bPu"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.random.manual_seed(RANDOM_STATE)\n",
        "\n",
        "train_dataset = DataWrapper(X_train, df_train['label'].values)\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "val_dataset = DataWrapper(X_val, df_val['label'].values)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "metadata": {
        "id": "fiYvO77F0bSD"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Fybh3zgE0zH4",
        "outputId": "3ece664d-2cea-4942-aebb-cb040c28b070"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Напишем код сети. Учитывая дисбаланс классов, метрика accuracy нам\n",
        "не подходит. Вместо неё будем использовать F1-score."
      ],
      "metadata": {
        "id": "L1lDk7Rq06UT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_nn(epochs=5, embedding_dim=128, hidden_size=64, lr=1e-3, threshold=0.5, use_last=True, return_model=False):\n",
        "\n",
        "    torch.random.manual_seed(RANDOM_STATE)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "    net = Net(vocab_size=MAX_WORDS, embedding_dim=embedding_dim, \n",
        "              out_dim=hidden_size, use_last=use_last, threshold=threshold).to(device)\n",
        "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "    criterion = nn.BCELoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        train_losses = np.array([])\n",
        "        test_losses = np.array([])\n",
        "        tp, fp, tn, fn = 0, 0, 0, 0\n",
        "\n",
        "        for i, (inputs, labels) in enumerate(train_loader):\n",
        "            net.train()\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(inputs)\n",
        "\n",
        "            loss = criterion(outputs, labels.float().view(-1, 1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_losses = np.append(train_losses, loss.item())\n",
        "\n",
        "            net.eval()\n",
        "            outputs = torch.squeeze((net(inputs) > threshold).int())\n",
        "\n",
        "            tp += ((labels == 1) & (outputs == 1)).sum().item()\n",
        "            tn += ((labels == 0) & (outputs == 0)).sum().item()\n",
        "            fp += ((labels == 0) & (outputs == 1)).sum().item()\n",
        "            fn += ((labels == 1) & (outputs == 0)).sum().item()\n",
        "\n",
        "        precision = tp / (tp + fp) if (tp + fp) != 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) != 0 else 0\n",
        "\n",
        "        f1_score = 2 * precision * recall / (precision + recall) if (precision + recall) != 0 else 0\n",
        "\n",
        "        print(f'Epoch [{epoch + 1}/{epochs}]. ' \\\n",
        "              f'Loss: {train_losses.mean():.3f}. ' \\\n",
        "              f'F1-score: {f1_score:.3f}', end='. ')\n",
        "\n",
        "        tp, fp, tn, fn = 0, 0, 0, 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for i, (inputs, labels) in enumerate(val_loader):\n",
        "\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = net(inputs)\n",
        "\n",
        "                loss = criterion(outputs, labels.float().view(-1, 1))\n",
        "                test_losses = np.append(test_losses, loss.item())\n",
        "\n",
        "                tp += ((labels == 1) & (torch.squeeze((outputs > threshold).int()) == 1)).sum()\n",
        "                tn += ((labels == 0) & (torch.squeeze((outputs > threshold).int()) == 0)).sum()\n",
        "                fp += ((labels == 0) & (torch.squeeze((outputs > threshold).int()) == 1)).sum()\n",
        "                fn += ((labels == 1) & (torch.squeeze((outputs > threshold).int()) == 0)).sum()\n",
        "\n",
        "        precision = tp / (tp + fp) if (tp + fp) != 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) != 0 else 0\n",
        "\n",
        "        f1_score = 2 * precision * recall / (precision + recall) if (precision + recall) != 0 else 0\n",
        "\n",
        "        print(f'Test loss: {test_losses.mean():.3f}. Test F1-score: {f1_score:.3f}. Precision: {precision:.3f}. Recall: {recall:.3f}')\n",
        "\n",
        "    print('Training is finished!')\n",
        "    if return_model:\n",
        "        return net"
      ],
      "metadata": {
        "id": "wEg3rgbu0zKt"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучим модель на 70 эпохах:"
      ],
      "metadata": {
        "id": "6zKmq9tz1CY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_nn(epochs=70, use_last=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-Bh2wSK0zNF",
        "outputId": "2bbdfef9-3f21-4745-b2da-37d8ec097075"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/70]. Loss: 0.454. F1-score: 0.098. Test loss: 0.265. Test F1-score: 0.000. Precision: 0.000. Recall: 0.000\n",
            "Epoch [2/70]. Loss: 0.263. F1-score: 0.000. Test loss: 0.251. Test F1-score: 0.000. Precision: 0.000. Recall: 0.000\n",
            "Epoch [3/70]. Loss: 0.254. F1-score: 0.000. Test loss: 0.242. Test F1-score: 0.000. Precision: 0.000. Recall: 0.000\n",
            "Epoch [4/70]. Loss: 0.236. F1-score: 0.000. Test loss: 0.212. Test F1-score: 0.000. Precision: 0.000. Recall: 0.000\n",
            "Epoch [5/70]. Loss: 0.206. F1-score: 0.000. Test loss: 0.180. Test F1-score: 0.000. Precision: 0.000. Recall: 0.000\n",
            "Epoch [6/70]. Loss: 0.182. F1-score: 0.157. Test loss: 0.159. Test F1-score: 0.484. Precision: 0.771. Recall: 0.353\n",
            "Epoch [7/70]. Loss: 0.162. F1-score: 0.602. Test loss: 0.145. Test F1-score: 0.529. Precision: 0.711. Recall: 0.422\n",
            "Epoch [8/70]. Loss: 0.148. F1-score: 0.641. Test loss: 0.138. Test F1-score: 0.578. Precision: 0.765. Recall: 0.464\n",
            "Epoch [9/70]. Loss: 0.142. F1-score: 0.666. Test loss: 0.140. Test F1-score: 0.551. Precision: 0.810. Recall: 0.417\n",
            "Epoch [10/70]. Loss: 0.131. F1-score: 0.689. Test loss: 0.136. Test F1-score: 0.585. Precision: 0.756. Recall: 0.478\n",
            "Epoch [11/70]. Loss: 0.125. F1-score: 0.716. Test loss: 0.131. Test F1-score: 0.596. Precision: 0.793. Recall: 0.478\n",
            "Epoch [12/70]. Loss: 0.122. F1-score: 0.724. Test loss: 0.131. Test F1-score: 0.590. Precision: 0.809. Recall: 0.464\n",
            "Epoch [13/70]. Loss: 0.116. F1-score: 0.746. Test loss: 0.128. Test F1-score: 0.606. Precision: 0.810. Recall: 0.484\n",
            "Epoch [14/70]. Loss: 0.111. F1-score: 0.756. Test loss: 0.130. Test F1-score: 0.644. Precision: 0.749. Recall: 0.565\n",
            "Epoch [15/70]. Loss: 0.108. F1-score: 0.767. Test loss: 0.126. Test F1-score: 0.645. Precision: 0.790. Recall: 0.545\n",
            "Epoch [16/70]. Loss: 0.104. F1-score: 0.781. Test loss: 0.128. Test F1-score: 0.646. Precision: 0.792. Recall: 0.545\n",
            "Epoch [17/70]. Loss: 0.101. F1-score: 0.791. Test loss: 0.125. Test F1-score: 0.645. Precision: 0.794. Recall: 0.542\n",
            "Epoch [18/70]. Loss: 0.098. F1-score: 0.806. Test loss: 0.127. Test F1-score: 0.657. Precision: 0.773. Recall: 0.571\n",
            "Epoch [19/70]. Loss: 0.097. F1-score: 0.808. Test loss: 0.123. Test F1-score: 0.641. Precision: 0.788. Recall: 0.540\n",
            "Epoch [20/70]. Loss: 0.094. F1-score: 0.814. Test loss: 0.124. Test F1-score: 0.642. Precision: 0.795. Recall: 0.538\n",
            "Epoch [21/70]. Loss: 0.093. F1-score: 0.824. Test loss: 0.129. Test F1-score: 0.640. Precision: 0.781. Recall: 0.542\n",
            "Epoch [22/70]. Loss: 0.088. F1-score: 0.826. Test loss: 0.131. Test F1-score: 0.642. Precision: 0.791. Recall: 0.540\n",
            "Epoch [23/70]. Loss: 0.088. F1-score: 0.838. Test loss: 0.130. Test F1-score: 0.622. Precision: 0.805. Recall: 0.507\n",
            "Epoch [24/70]. Loss: 0.087. F1-score: 0.842. Test loss: 0.131. Test F1-score: 0.651. Precision: 0.803. Recall: 0.547\n",
            "Epoch [25/70]. Loss: 0.084. F1-score: 0.861. Test loss: 0.129. Test F1-score: 0.652. Precision: 0.792. Recall: 0.554\n",
            "Epoch [26/70]. Loss: 0.081. F1-score: 0.864. Test loss: 0.135. Test F1-score: 0.643. Precision: 0.798. Recall: 0.538\n",
            "Epoch [27/70]. Loss: 0.079. F1-score: 0.865. Test loss: 0.137. Test F1-score: 0.651. Precision: 0.781. Recall: 0.558\n",
            "Epoch [28/70]. Loss: 0.078. F1-score: 0.879. Test loss: 0.129. Test F1-score: 0.665. Precision: 0.771. Recall: 0.585\n",
            "Epoch [29/70]. Loss: 0.076. F1-score: 0.882. Test loss: 0.129. Test F1-score: 0.671. Precision: 0.764. Recall: 0.598\n",
            "Epoch [30/70]. Loss: 0.078. F1-score: 0.884. Test loss: 0.128. Test F1-score: 0.662. Precision: 0.772. Recall: 0.580\n",
            "Epoch [31/70]. Loss: 0.074. F1-score: 0.890. Test loss: 0.133. Test F1-score: 0.681. Precision: 0.768. Recall: 0.612\n",
            "Epoch [32/70]. Loss: 0.074. F1-score: 0.895. Test loss: 0.131. Test F1-score: 0.671. Precision: 0.764. Recall: 0.598\n",
            "Epoch [33/70]. Loss: 0.072. F1-score: 0.902. Test loss: 0.137. Test F1-score: 0.662. Precision: 0.777. Recall: 0.576\n",
            "Epoch [34/70]. Loss: 0.070. F1-score: 0.907. Test loss: 0.135. Test F1-score: 0.655. Precision: 0.785. Recall: 0.562\n",
            "Epoch [35/70]. Loss: 0.068. F1-score: 0.908. Test loss: 0.134. Test F1-score: 0.660. Precision: 0.776. Recall: 0.574\n",
            "Epoch [36/70]. Loss: 0.068. F1-score: 0.912. Test loss: 0.137. Test F1-score: 0.663. Precision: 0.782. Recall: 0.576\n",
            "Epoch [37/70]. Loss: 0.066. F1-score: 0.915. Test loss: 0.136. Test F1-score: 0.664. Precision: 0.765. Recall: 0.587\n",
            "Epoch [38/70]. Loss: 0.064. F1-score: 0.919. Test loss: 0.145. Test F1-score: 0.636. Precision: 0.789. Recall: 0.533\n",
            "Epoch [39/70]. Loss: 0.063. F1-score: 0.924. Test loss: 0.139. Test F1-score: 0.686. Precision: 0.769. Recall: 0.618\n",
            "Epoch [40/70]. Loss: 0.062. F1-score: 0.924. Test loss: 0.144. Test F1-score: 0.652. Precision: 0.775. Recall: 0.562\n",
            "Epoch [41/70]. Loss: 0.059. F1-score: 0.927. Test loss: 0.140. Test F1-score: 0.672. Precision: 0.766. Recall: 0.598\n",
            "Epoch [42/70]. Loss: 0.059. F1-score: 0.933. Test loss: 0.142. Test F1-score: 0.659. Precision: 0.786. Recall: 0.567\n",
            "Epoch [43/70]. Loss: 0.058. F1-score: 0.934. Test loss: 0.143. Test F1-score: 0.669. Precision: 0.763. Recall: 0.596\n",
            "Epoch [44/70]. Loss: 0.056. F1-score: 0.940. Test loss: 0.147. Test F1-score: 0.670. Precision: 0.780. Recall: 0.587\n",
            "Epoch [45/70]. Loss: 0.055. F1-score: 0.938. Test loss: 0.153. Test F1-score: 0.673. Precision: 0.796. Recall: 0.583\n",
            "Epoch [46/70]. Loss: 0.055. F1-score: 0.941. Test loss: 0.156. Test F1-score: 0.676. Precision: 0.740. Recall: 0.623\n",
            "Epoch [47/70]. Loss: 0.055. F1-score: 0.942. Test loss: 0.152. Test F1-score: 0.689. Precision: 0.749. Recall: 0.638\n",
            "Epoch [48/70]. Loss: 0.052. F1-score: 0.944. Test loss: 0.155. Test F1-score: 0.674. Precision: 0.798. Recall: 0.583\n",
            "Epoch [49/70]. Loss: 0.052. F1-score: 0.953. Test loss: 0.146. Test F1-score: 0.679. Precision: 0.767. Recall: 0.609\n",
            "Epoch [50/70]. Loss: 0.051. F1-score: 0.951. Test loss: 0.155. Test F1-score: 0.680. Precision: 0.740. Recall: 0.629\n",
            "Epoch [51/70]. Loss: 0.049. F1-score: 0.955. Test loss: 0.146. Test F1-score: 0.681. Precision: 0.775. Recall: 0.607\n",
            "Epoch [52/70]. Loss: 0.049. F1-score: 0.956. Test loss: 0.154. Test F1-score: 0.687. Precision: 0.779. Recall: 0.614\n",
            "Epoch [53/70]. Loss: 0.048. F1-score: 0.958. Test loss: 0.154. Test F1-score: 0.691. Precision: 0.749. Recall: 0.641\n",
            "Epoch [54/70]. Loss: 0.048. F1-score: 0.964. Test loss: 0.157. Test F1-score: 0.688. Precision: 0.769. Recall: 0.623\n",
            "Epoch [55/70]. Loss: 0.044. F1-score: 0.961. Test loss: 0.154. Test F1-score: 0.689. Precision: 0.759. Recall: 0.632\n",
            "Epoch [56/70]. Loss: 0.049. F1-score: 0.963. Test loss: 0.156. Test F1-score: 0.679. Precision: 0.790. Recall: 0.596\n",
            "Epoch [57/70]. Loss: 0.046. F1-score: 0.965. Test loss: 0.158. Test F1-score: 0.676. Precision: 0.750. Recall: 0.616\n",
            "Epoch [58/70]. Loss: 0.045. F1-score: 0.968. Test loss: 0.165. Test F1-score: 0.676. Precision: 0.785. Recall: 0.594\n",
            "Epoch [59/70]. Loss: 0.044. F1-score: 0.968. Test loss: 0.156. Test F1-score: 0.671. Precision: 0.783. Recall: 0.587\n",
            "Epoch [60/70]. Loss: 0.043. F1-score: 0.972. Test loss: 0.172. Test F1-score: 0.662. Precision: 0.781. Recall: 0.574\n",
            "Epoch [61/70]. Loss: 0.044. F1-score: 0.973. Test loss: 0.155. Test F1-score: 0.688. Precision: 0.762. Recall: 0.627\n",
            "Epoch [62/70]. Loss: 0.040. F1-score: 0.976. Test loss: 0.167. Test F1-score: 0.673. Precision: 0.768. Recall: 0.598\n",
            "Epoch [63/70]. Loss: 0.042. F1-score: 0.976. Test loss: 0.160. Test F1-score: 0.683. Precision: 0.770. Recall: 0.614\n",
            "Epoch [64/70]. Loss: 0.042. F1-score: 0.974. Test loss: 0.160. Test F1-score: 0.679. Precision: 0.753. Recall: 0.618\n",
            "Epoch [65/70]. Loss: 0.040. F1-score: 0.977. Test loss: 0.168. Test F1-score: 0.668. Precision: 0.788. Recall: 0.580\n",
            "Epoch [66/70]. Loss: 0.038. F1-score: 0.982. Test loss: 0.160. Test F1-score: 0.678. Precision: 0.768. Recall: 0.607\n",
            "Epoch [67/70]. Loss: 0.039. F1-score: 0.979. Test loss: 0.167. Test F1-score: 0.683. Precision: 0.749. Recall: 0.627\n",
            "Epoch [68/70]. Loss: 0.039. F1-score: 0.981. Test loss: 0.171. Test F1-score: 0.690. Precision: 0.780. Recall: 0.618\n",
            "Epoch [69/70]. Loss: 0.039. F1-score: 0.982. Test loss: 0.170. Test F1-score: 0.673. Precision: 0.772. Recall: 0.596\n",
            "Epoch [70/70]. Loss: 0.038. F1-score: 0.982. Test loss: 0.172. Test F1-score: 0.685. Precision: 0.760. Recall: 0.623\n",
            "Training is finished!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Модель GRU показала результат лучше, чем 1D свёртки из прошлого практического\n",
        "задания, F1-score выше где-то на 8%. Также она оказалась чуть лучше, чем модель\n",
        "LSTM (выявлено в результате перебора гиперпараметров). По логам видно, что\n",
        "переобучение снова присутствует. Интересно, что модель GRU положительно отреагировала\n",
        "на увеличение размера словаря и длины последовательности, тогда как свёрточная сеть\n",
        "никак на это не реагировала.\n",
        "Финальную модель обучим на 30 эпохах, где у нас относительно малый тест лосс\n",
        "и относительно высокая метрика. Так же, как и в прошлый раз, снизим порог\n",
        "классификации для получения более высокого Recall, который важен в нашей задаче:"
      ],
      "metadata": {
        "id": "Wn2njzEZ4xvV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_net = train_nn(epochs=30, threshold=0.25, return_model=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XCcorD74sgt",
        "outputId": "cc053bbc-20d7-4187-f875-e6533283a166"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/30]. Loss: 0.454. F1-score: 0.124. Test loss: 0.265. Test F1-score: 0.000. Precision: 0.000. Recall: 0.000\n",
            "Epoch [2/30]. Loss: 0.263. F1-score: 0.000. Test loss: 0.251. Test F1-score: 0.000. Precision: 0.000. Recall: 0.000\n",
            "Epoch [3/30]. Loss: 0.254. F1-score: 0.002. Test loss: 0.242. Test F1-score: 0.000. Precision: 0.000. Recall: 0.000\n",
            "Epoch [4/30]. Loss: 0.236. F1-score: 0.008. Test loss: 0.212. Test F1-score: 0.004. Precision: 0.143. Recall: 0.002\n",
            "Epoch [5/30]. Loss: 0.206. F1-score: 0.377. Test loss: 0.180. Test F1-score: 0.452. Precision: 0.379. Recall: 0.560\n",
            "Epoch [6/30]. Loss: 0.182. F1-score: 0.542. Test loss: 0.159. Test F1-score: 0.512. Precision: 0.450. Recall: 0.594\n",
            "Epoch [7/30]. Loss: 0.162. F1-score: 0.615. Test loss: 0.145. Test F1-score: 0.567. Precision: 0.558. Recall: 0.576\n",
            "Epoch [8/30]. Loss: 0.148. F1-score: 0.662. Test loss: 0.138. Test F1-score: 0.603. Precision: 0.611. Recall: 0.596\n",
            "Epoch [9/30]. Loss: 0.142. F1-score: 0.693. Test loss: 0.140. Test F1-score: 0.616. Precision: 0.684. Recall: 0.560\n",
            "Epoch [10/30]. Loss: 0.131. F1-score: 0.719. Test loss: 0.136. Test F1-score: 0.629. Precision: 0.657. Recall: 0.603\n",
            "Epoch [11/30]. Loss: 0.125. F1-score: 0.733. Test loss: 0.131. Test F1-score: 0.635. Precision: 0.665. Recall: 0.607\n",
            "Epoch [12/30]. Loss: 0.122. F1-score: 0.752. Test loss: 0.131. Test F1-score: 0.650. Precision: 0.711. Recall: 0.598\n",
            "Epoch [13/30]. Loss: 0.116. F1-score: 0.764. Test loss: 0.128. Test F1-score: 0.647. Precision: 0.687. Recall: 0.612\n",
            "Epoch [14/30]. Loss: 0.111. F1-score: 0.780. Test loss: 0.130. Test F1-score: 0.642. Precision: 0.623. Recall: 0.663\n",
            "Epoch [15/30]. Loss: 0.108. F1-score: 0.788. Test loss: 0.126. Test F1-score: 0.657. Precision: 0.656. Recall: 0.658\n",
            "Epoch [16/30]. Loss: 0.104. F1-score: 0.797. Test loss: 0.128. Test F1-score: 0.667. Precision: 0.677. Recall: 0.656\n",
            "Epoch [17/30]. Loss: 0.101. F1-score: 0.806. Test loss: 0.125. Test F1-score: 0.659. Precision: 0.652. Recall: 0.665\n",
            "Epoch [18/30]. Loss: 0.098. F1-score: 0.813. Test loss: 0.127. Test F1-score: 0.673. Precision: 0.671. Recall: 0.674\n",
            "Epoch [19/30]. Loss: 0.097. F1-score: 0.823. Test loss: 0.123. Test F1-score: 0.663. Precision: 0.663. Recall: 0.663\n",
            "Epoch [20/30]. Loss: 0.094. F1-score: 0.829. Test loss: 0.124. Test F1-score: 0.677. Precision: 0.693. Recall: 0.661\n",
            "Epoch [21/30]. Loss: 0.093. F1-score: 0.831. Test loss: 0.129. Test F1-score: 0.677. Precision: 0.717. Recall: 0.641\n",
            "Epoch [22/30]. Loss: 0.088. F1-score: 0.844. Test loss: 0.131. Test F1-score: 0.682. Precision: 0.731. Recall: 0.638\n",
            "Epoch [23/30]. Loss: 0.088. F1-score: 0.854. Test loss: 0.130. Test F1-score: 0.680. Precision: 0.740. Recall: 0.629\n",
            "Epoch [24/30]. Loss: 0.087. F1-score: 0.861. Test loss: 0.131. Test F1-score: 0.680. Precision: 0.734. Recall: 0.634\n",
            "Epoch [25/30]. Loss: 0.084. F1-score: 0.867. Test loss: 0.129. Test F1-score: 0.672. Precision: 0.679. Recall: 0.665\n",
            "Epoch [26/30]. Loss: 0.081. F1-score: 0.869. Test loss: 0.135. Test F1-score: 0.675. Precision: 0.729. Recall: 0.629\n",
            "Epoch [27/30]. Loss: 0.079. F1-score: 0.878. Test loss: 0.137. Test F1-score: 0.680. Precision: 0.719. Recall: 0.645\n",
            "Epoch [28/30]. Loss: 0.078. F1-score: 0.875. Test loss: 0.129. Test F1-score: 0.677. Precision: 0.673. Recall: 0.681\n",
            "Epoch [29/30]. Loss: 0.076. F1-score: 0.886. Test loss: 0.129. Test F1-score: 0.677. Precision: 0.650. Recall: 0.708\n",
            "Epoch [30/30]. Loss: 0.078. F1-score: 0.886. Test loss: 0.128. Test F1-score: 0.680. Precision: 0.655. Recall: 0.708\n",
            "Training is finished!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "По сравнению с предыдущим решением на свёртках, мы находим почти столько же\n",
        "оскорбительных твитов (64-65%). Но показатель точности теперь выше на 21%\n",
        "(65% против 44%). В общем, эти результаты всё равно являются не очень хорошими для\n",
        "готовой модели. Снова будем считать, что основной причиной является недостаток данных\n",
        "(25 тысяч примеров в обучающей выборке, из которых всего 1800 положительного\n",
        "класса)."
      ],
      "metadata": {
        "id": "zzOcNgNr45TN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPEFLXqy4skF",
        "outputId": "5804cba3-f32b-4848-a3cc-ba11b9766447"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    23775\n",
              "1     1794\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Предсказание модели:"
      ],
      "metadata": {
        "id": "KnQU3eVF4-Eq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_net.predict(X_val[np.newaxis, 0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ky4RIIXC4snc",
        "outputId": "524ae4ba-f3ac-4a81-f492-099d6d605522"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1, dtype=torch.int32)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    }
  ]
}