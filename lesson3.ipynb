{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn import datasets as dss\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "import math\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "A6QrJlT_rWHV"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class housing_ds(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, init_dataset, init_target, transform=None):\n",
        "        self._base_dataset = torch.from_numpy(init_dataset).type(torch.float)\n",
        "        self._base_targets = torch.from_numpy(init_target).type(torch.float)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._base_dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        features = self._base_dataset[idx]\n",
        "        target = self._base_targets[idx]\n",
        "\n",
        "        if self.transform is not None:\n",
        "            features = self.transform(features)\n",
        "\n",
        "        return features, target"
      ],
      "metadata": {
        "id": "WAUDDIxPrWJm"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Perceptron(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, activation=\"relu\"):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(input_dim, output_dim)\n",
        "        self.activation = activation\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        if self.activation == \"relu\":\n",
        "            return F.relu(x)\n",
        "        if self.activation == \"sigmoid\":\n",
        "            return F.sigmoid(x)\n",
        "        if self.activation == \"leaky_relu\":\n",
        "            return F.leaky_relu(x)\n",
        "        raise RuntimeError\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.fc1 = Perceptron(input_dim, hidden_dim, 'leaky_relu')\n",
        "        self.bn = nn.BatchNorm1d(hidden_dim)\n",
        "        self.dp = nn.Dropout(0.15)\n",
        "        self.fc2 = Perceptron(hidden_dim, 1, 'leaky_relu')\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.dp(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "m_M1tJzprWLr"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = dss.fetch_california_housing()"
      ],
      "metadata": {
        "id": "y4ahb_RmrWNi"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data['data'], data['target'], test_size = 0.25, random_state = 13)"
      ],
      "metadata": {
        "id": "5_YQLdQ-rWPn"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = housing_ds(X_train, y_train)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=150, shuffle=False)"
      ],
      "metadata": {
        "id": "IpFzeRUfrWRZ"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = housing_ds(X_test, y_test)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=10, shuffle=False)"
      ],
      "metadata": {
        "id": "H6J3g7IBrWTf"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = FeedForward(8, 8)\n",
        "\n",
        "# optimizer = torch.optim.SGD(net.parameters(), lr=0.001)\n",
        "# optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
        "optimizer = torch.optim.RMSprop(net.parameters(), lr=0.001)\n",
        "\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "4PCpnqObrvDr"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    net.cuda()"
      ],
      "metadata": {
        "id": "u0fOIG2UrvF9"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss, running_items, r2 = 0.0, 0.0, 0.0\n",
        "\n",
        "    for i, data in enumerate(train_loader):\n",
        "        fets, target = data[0], data[1]\n",
        "\n",
        "        # обнуляем градиент\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = net(fets)\n",
        "        loss = criterion(outputs, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # выводим статистику о процессе обучения\n",
        "        running_loss += loss.item()\n",
        "        running_items += len(target)\n",
        "\n",
        "        predict = outputs.data.numpy()\n",
        "        tr_target = target.view(target.shape[0], 1).numpy()\n",
        "        r2 += r2_score(tr_target, predict)\n",
        "\n",
        "        # выводим статистику о процессе обучения\n",
        "        if i % 30 == 0:\n",
        "            net.eval()\n",
        "\n",
        "            data = list(test_loader)[0]\n",
        "\n",
        "            test_outputs = net(data[0])\n",
        "            test_predict = test_outputs.data.numpy()\n",
        "            te_target = data[1].view(data[1].shape[0], 1)\n",
        "            test_r2 = r2_score(te_target, test_predict)\n",
        "\n",
        "            print(f'Epoch [{epoch + 1}/{num_epochs}]. ' \\\n",
        "                  f'Step [{i + 1}/{len(train_loader)}]. ' \\\n",
        "                  f'Loss: {running_loss / running_items:.3f}. ' \\\n",
        "                  f'r2: {r2:.3f}. ' \\\n",
        "                  f'Test r2: {test_r2:.3f}')\n",
        "\n",
        "            running_loss, running_items, r2 = 0.0, 0.0, 0.0\n",
        "\n",
        "            net.train()\n",
        "\n",
        "print('Training is finished!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEs570_5rvIT",
        "outputId": "568b8df9-6f6d-449d-f86a-17a56df95aac"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10]. Step [1/104]. Loss: 0.040. r2: -3.102. Test r2: -4.825\n",
            "Epoch [1/10]. Step [31/104]. Loss: 0.033. r2: -86.344. Test r2: -3.527\n",
            "Epoch [1/10]. Step [61/104]. Loss: 0.030. r2: -74.137. Test r2: -3.881\n",
            "Epoch [1/10]. Step [91/104]. Loss: 0.026. r2: -62.145. Test r2: -2.297\n",
            "Epoch [2/10]. Step [1/104]. Loss: 0.025. r2: -1.573. Test r2: -1.745\n",
            "Epoch [2/10]. Step [31/104]. Loss: 0.020. r2: -41.227. Test r2: -2.327\n",
            "Epoch [2/10]. Step [61/104]. Loss: 0.018. r2: -31.272. Test r2: -0.399\n",
            "Epoch [2/10]. Step [91/104]. Loss: 0.016. r2: -25.368. Test r2: -0.115\n",
            "Epoch [3/10]. Step [1/104]. Loss: 0.017. r2: -0.841. Test r2: -1.272\n",
            "Epoch [3/10]. Step [31/104]. Loss: 0.014. r2: -21.084. Test r2: -0.141\n",
            "Epoch [3/10]. Step [61/104]. Loss: 0.014. r2: -17.391. Test r2: 0.098\n",
            "Epoch [3/10]. Step [91/104]. Loss: 0.012. r2: -13.420. Test r2: -0.012\n",
            "Epoch [4/10]. Step [1/104]. Loss: 0.013. r2: -0.277. Test r2: -0.031\n",
            "Epoch [4/10]. Step [31/104]. Loss: 0.011. r2: -9.394. Test r2: -0.170\n",
            "Epoch [4/10]. Step [61/104]. Loss: 0.011. r2: -7.598. Test r2: -0.104\n",
            "Epoch [4/10]. Step [91/104]. Loss: 0.011. r2: -8.141. Test r2: -0.203\n",
            "Epoch [5/10]. Step [1/104]. Loss: 0.012. r2: -0.189. Test r2: -0.205\n",
            "Epoch [5/10]. Step [31/104]. Loss: 0.010. r2: -7.288. Test r2: -0.217\n",
            "Epoch [5/10]. Step [61/104]. Loss: 0.010. r2: -5.078. Test r2: -0.126\n",
            "Epoch [5/10]. Step [91/104]. Loss: 0.010. r2: -5.074. Test r2: -0.153\n",
            "Epoch [6/10]. Step [1/104]. Loss: 0.011. r2: -0.148. Test r2: -0.210\n",
            "Epoch [6/10]. Step [31/104]. Loss: 0.010. r2: -4.326. Test r2: -0.182\n",
            "Epoch [6/10]. Step [61/104]. Loss: 0.010. r2: -4.108. Test r2: -0.159\n",
            "Epoch [6/10]. Step [91/104]. Loss: 0.010. r2: -4.051. Test r2: -0.247\n",
            "Epoch [7/10]. Step [1/104]. Loss: 0.012. r2: -0.333. Test r2: -0.180\n",
            "Epoch [7/10]. Step [31/104]. Loss: 0.010. r2: -3.845. Test r2: -0.150\n",
            "Epoch [7/10]. Step [61/104]. Loss: 0.010. r2: -3.730. Test r2: -0.206\n",
            "Epoch [7/10]. Step [91/104]. Loss: 0.010. r2: -3.710. Test r2: -0.205\n",
            "Epoch [8/10]. Step [1/104]. Loss: 0.011. r2: -0.057. Test r2: -0.245\n",
            "Epoch [8/10]. Step [31/104]. Loss: 0.009. r2: -3.680. Test r2: -0.146\n",
            "Epoch [8/10]. Step [61/104]. Loss: 0.010. r2: -3.349. Test r2: -0.171\n",
            "Epoch [8/10]. Step [91/104]. Loss: 0.009. r2: -3.182. Test r2: -0.227\n",
            "Epoch [9/10]. Step [1/104]. Loss: 0.010. r2: -0.057. Test r2: -0.231\n",
            "Epoch [9/10]. Step [31/104]. Loss: 0.009. r2: -2.645. Test r2: -0.186\n",
            "Epoch [9/10]. Step [61/104]. Loss: 0.010. r2: -2.896. Test r2: -0.184\n",
            "Epoch [9/10]. Step [91/104]. Loss: 0.009. r2: -2.083. Test r2: -0.174\n",
            "Epoch [10/10]. Step [1/104]. Loss: 0.012. r2: -0.328. Test r2: -0.256\n",
            "Epoch [10/10]. Step [31/104]. Loss: 0.009. r2: -2.211. Test r2: -0.176\n",
            "Epoch [10/10]. Step [61/104]. Loss: 0.009. r2: -2.299. Test r2: -0.198\n",
            "Epoch [10/10]. Step [91/104]. Loss: 0.009. r2: -1.939. Test r2: -0.189\n",
            "Training is finished!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "C помощью оптимизатора Адам модель быстрее находит решение, в целом модель не очень хорошо справляется с задачей регрессии."
      ],
      "metadata": {
        "id": "gdm6ZCfHsBo-"
      }
    }
  ]
}